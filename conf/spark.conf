# Spark home
hibench.spark.home      /home/cwei/project/spark-2.0.1-bin-hadoop2.7
#hibench.spark.home      /home/cwei/project/spark-DynamicMemory

# Spark version. Supported value: spark1.6, spark2.0
hibench.spark.version   spark2.0

# Spark master
#   standalone mode: `spark://xxx:7077`
#   YARN mode: `yarn-client`
#   unset: fallback to `local[1]`
hibench.spark.master    yarn-client

# executor number and cores when running on Yarn
hibench.yarn.executor.num     1
hibench.yarn.executor.cores   20

# executor and driver memory in standalone & YARN mode
spark.executor.memory         64g
spark.driver.memory           4g
##spark fraction memory
spark.memory.fraction         0.75
spark.memory.offHeap.enabled  false
##gc tuning
spark.executor.extraJavaOptions  -XX:+PrintGCDetails -XX:+PrintGCTimeStamps 
#-XX:MinHeapFreeRatio=20 



##-XX:GCTimeRatio=59 
##-XX:MinHeapFreeRatio=10  -XX:MaxHeapFreeRatio=20

#log
spark.eventLog.enabled                     true
spark.eventLog.dir                         hdfs://disco-0021:9000/spark/eventlog

#node label
#spark.yarn.am.nodeLabelExpression          flex

# set spark parallelism property according to hibench's parallelism value
spark.default.parallelism                  ${hibench.default.map.parallelism}

# dynamic memory
spark.memory.dynamicResize.enabled          true
spark.memory.dynamicResize.interval         5000
spark.memory.dynamicResize.path             /sys/fs/cgroup/memory/memory.limit_in_bytes

# set spark sql's default shuffle partitions according to hibench's parallelism value
spark.sql.shuffle.partitions  ${hibench.default.map.parallelism}
